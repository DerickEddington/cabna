bits 64
default rel


%include "cabna/conv"


global _start
global alloc_task
global sched_task
global supply_retval
global exec_avail
global free_pet__exec_avail

%ifdef statistics_collection
global print_stats
extern printf
%endif

extern main
extern bug


; It is assumed that all Cabna code and data is located in 32-bit address space,
; which allows assuming Cabna addresses fit in 32 bits.  This is taken advantage
; of to use 32-bit operations instead of 64-bit, as the processor manufacturers
; recommend, when possible, for optimization, and also to fit two values in r15.
; Cabna is still a 64-bit system intended for 64-bit use, and 64-bit addresses
; and operations are used for users' stuff and strucs that might be allocated in
; 64-bit space.


; Users' responsibilities:
;  1) Task strucs must not be in more than one stack at a time.
;  2) Task strucs must not be in the same stack more than once.
;  3) The memory allocated by the OS for task strucs must never be returned to
;     the OS.
; It is assumed that users obey these responsibilities.




section .text


proc alloc_task:
  ; Pop a free task struc from the thread's allocatable-tasks stack, or see if
  ; other threads have freed some of the thread's strucs, or allocate more
  ; memory from the OS, and return to ret_rsi with task pointer in arg1_rdi.
  ; Each thread has its own private allocatable-tasks stack, so if that's used
  ; concurrency-safety is not needed.
  ; Used registers: rax, rcx, rdx, rsi, rdi, r8, r9, r10, r11.

%ifdef statistics_collection
  mov ecx, 1
  lock xadd [statistics + 0 + stats.in_use], rcx
  add rcx, 1
  mov rax, [statistics + 0 + stats.used_max]
.retry_max:
  cmp rcx, rax
  jbe .not_used_max
  lock cmpxchg [statistics + 0 + stats.used_max], rcx
  jne .retry_max
.not_used_max:
%endif

  stat add qword [statistics + tid_r15d + stats.allocated], 1

  mov arg1_rdi, [allocatables + tid_r15d]
  test arg1_rdi, arg1_rdi
  unlikely jz .orphans

.done:
  ; The next, which might be null, becomes the head.
  mov rax, [arg1_rdi + task.next]
  mov [allocatables + tid_r15d], rax
  mov qword [arg1_rdi + task.next], 0
  stat sub qword [statistics + tid_r15d + stats.alloc_s_size], 1
  jmp_ind ret_rsi

.orphans:
  mov rax, [orphans + tid_r15d]
  test rax, rax
  jz .get_new_space
  ; The field will still be non-null if another thread changes it.
  ; arg1_rdi already null.
  xchg [orphans + tid_r15d], arg1_rdi  ; Locking automatically done for xchg.
%ifdef statistics_collection
  mov rax, arg1_rdi
  xor ecx, ecx
.orphans_size:
  add rcx, 1
  mov rax, [rax + task.next]
  test rax, rax
  jnz .orphans_size
  mov [statistics + tid_r15d + stats.alloc_s_size], rcx
  cmp rcx, [statistics + tid_r15d + stats.alloc_s_max]
  jbe .not_alloc_s_max
  mov [statistics + tid_r15d + stats.alloc_s_max], rcx
.not_alloc_s_max:
  add qword [statistics + tid_r15d + stats.alloc_orphans], 1
%endif
  jmp .done

.get_new_space:
  ; Get some more space from the OS, divide into blocks of task strucs, link
  ; together, push-at-once, and return a struc.  The unset fields of the new
  ; strucs are null because mmap zeros, as needed for future operations.

  ; Save registers.
  ;mov ?, r9
  ;mov ?, r8
  ;mov ?, r10
  ;mov ?, rdx
  mov [allocatables + tid_r15d], ret_rsi  ; Just a temporary location.
  ;mov ?, rdi
  ;mov ?, rax  ; syscall destroys
  ;mov ?, rcx  ; syscall destroys
  ;mov ?, r11  ; syscall destroys

  ; mmap a space.
  xor r9d, r9d                     ; pgoffset
  mov r8, dword -1                 ; fd
  mov r10d, 0x22                   ; flags = MAP_PRIVATE | MAP_ANONYMOUS
  mov edx, 3                       ; prot = PROT_READ | PROT_WRITE
  mov esi, mmap_tasks * task_size  ; length
  xor edi, edi                     ; addr = NULL
  mov eax, 9                       ; mmap syscall number
  syscall
  cmp rax, -4096
  ja .mmap_failed

  ; Reserve first struc for return value.
  mov arg1_rdi, rax
  mov [rax + task.owner], tid_r15d
  ; Divide remaining space into task strucs, and link together.
  add rax, rsi  ; End of the space.
  sub rax, task_size  ; Tail struc is the last block.
  xor edx, edx
.divide_and_link:
  mov [rax + task.owner], tid_r15d
  mov [rax + task.next], rdx
  mov rdx, rax
  sub rax, task_size
  cmp rax, arg1_rdi
  ja .divide_and_link
  mov ret_rsi, [allocatables + tid_r15d]  ; Restore saved.
  mov [allocatables + tid_r15d], rdx
%ifdef statistics_collection
  mov eax, mmap_tasks - 1
  mov [statistics + tid_r15d + stats.alloc_s_size], rax
  cmp rax, [statistics + tid_r15d + stats.alloc_s_max]
  jbe .not_alloc_s_max_2
  mov [statistics + tid_r15d + stats.alloc_s_max], rax
.not_alloc_s_max_2:
  add qword [statistics + tid_r15d + stats.mmap], 1
%endif
  jmp_ind ret_rsi

.mmap_failed:
  ; TODO: Negated error code is in rax, print to stderr, and do something...
  jmp bug




proc supply_retval:
  ; Return a value to the currently executing task's waiting receiver task,
  ; argument in arg1_rdi.  If the receiver task gets its final value, schedule
  ; the task for execution.  Return to ret_rsi.
  ; Used registers: rax, rdx, rsi, rdi.

  ; No other threads will access our currently executing task struc, so we can
  ; access it without concurrency concern.
  mov rax, [cet_r14 + task.rcvr]
  mov edx, [cet_r14 + task.ridx]  ; 32-bit alright.
  ; No other threads will access this field in rcvr, so we can access it without
  ; concurrency concern.
  mov [rax + task.args + 8 * rdx], arg1_rdi
  ; Other threads will access the .need field, so we must atomically decrement
  ; it.
  lock sub dword [rax + task.need], 1  ; 32-bit alright.
  cmovz arg1_rdi, rax  ; For sched_task.
  ; Supplied the final needed argument to rcvr, so schedule rcvr for execution.
  jz sched_task  ; ret_rsi already set.
  ; Receiver needs more.
  jmp_ind ret_rsi




proc sched_task:
  ; Push a task in the thread's executable-tasks stack, or if the stack already
  ; has at least one task and another thread needs a task, try to give the task
  ; to the needy thread.  Argument in arg1_rdi, and return to ret_rsi.
  ; Used registers: rax, rdx, rsi, rdi.

  stat add qword [statistics + tid_r15d + stats.sched_calls], 1

  mov rax, [executables + tid_r15d]
  test rax, rax
  jz .in_mine_empty

  ; Check if another thread needs a task.
  mov rdx, [needy]
  test rdx, rdx
  jnz .give

.in_mine:
  mov [arg1_rdi + task.next], rax
.in_mine_empty:
  mov [executables + tid_r15d], arg1_rdi
%ifdef statistics_collection
  add qword [statistics + tid_r15d + stats.sched_mine], 1
  mov rax, [statistics + tid_r15d + stats.exec_s_size]
  add rax, 1
  mov [statistics + tid_r15d + stats.exec_s_size], rax
  cmp rax, [statistics + tid_r15d + stats.exec_s_max]
  jbe .not_max
  mov [statistics + tid_r15d + stats.exec_s_max], rax
.not_max:
%endif
  jmp_ind ret_rsi

.give:
  xor edx, edx
  xchg [needy], rdx  ; Locking automatically done for xchg.
  test rdx, rdx
  unlikely jz .in_mine
  mov [gifts + edx], arg1_rdi
  jmp_ind ret_rsi




proc free_pet__exec_avail:
  ; Free the previously executing task by pushing it in the thread's
  ; allocatable-tasks stack; or if the struc belongs to another thread, give it
  ; to the owner; and continue into exec_avail.  Each thread has its own private
  ; allocatable-tasks stack, so if that's used concurrency-safety is not needed.
  ; Used registers: rax, rdx, and those of exec_avail.

  stat lock sub qword [statistics + 0 + stats.in_use], 1
  stat add qword [statistics + tid_r15d + stats.freed], 1

  mov edx, [cet_r14 + task.owner]
  cmp edx, tid_r15d
  jne .orphan

  mov rax, [allocatables + tid_r15d]
  mov [cet_r14 + task.next], rax
  mov [allocatables + tid_r15d], cet_r14

%ifdef statistics_collection
  mov rax, [statistics + tid_r15d + stats.alloc_s_size]
  add rax, 1
  mov [statistics + tid_r15d + stats.alloc_s_size], rax
  cmp rax, [statistics + tid_r15d + stats.alloc_s_max]
  jbe .not_max
  mov [statistics + tid_r15d + stats.alloc_s_max], rax
.not_max:
%endif

  jmp exec_avail

.orphan:
  mov rax, [orphans + edx]
.retry:
  ; pause  ; Not needed, I think, because the lock cmpxchg is always done.
  mov [cet_r14 + task.next], rax
  lock cmpxchg [orphans + edx], cet_r14
  jne .retry
  stat add qword [statistics + tid_r15d + stats.freed_orphans], 1
  jmp exec_avail




proc exec_avail:
  ; Pop a task from the thread's executable-tasks stack, or indicate that the
  ; thread needs a task and wait for one, then execute the task with cet_r14 set
  ; to the task.
  ; Used registers: rax, r14.

  stat add qword [statistics + tid_r15d + stats.execute_calls], 1

  mov cet_r14, [executables + tid_r15d]
  test cet_r14, cet_r14
  jz .empty

  ; The next, which might be null, becomes the head.
  mov rax, [cet_r14 + task.next]
  mov [executables + tid_r15d], rax
  mov qword [cet_r14 + task.next], 0

  stat sub qword [statistics + tid_r15d + stats.exec_s_size], 1
  stat add qword [statistics + tid_r15d + stats.executed_mine], 1

  ; Execute the task's instructions.  Tasks are responsible for giving control
  ; back to exec_evail.
  jmp_ind [cet_r14 + task.exec]

.empty:
  pause
  mov rax, [needy]
  test rax, rax
  unlikely jnz .empty
  lock cmpxchg [needy], needy_tid_r15
  unlikely jne .empty
.wait:
  pause
  mov cet_r14, [gifts + tid_r15d]
  test cet_r14, cet_r14
  jz .wait
  mov [gifts + tid_r15d], rax  ; rax is null.
  stat add qword [statistics + tid_r15d + stats.needy], 1
  ; Execute the task's instructions.  Tasks are responsible for giving control
  ; back to exec_evail.
  jmp_ind [cet_r14 + task.exec]




proc _start:
  ; Entry point.

  xor ebp, ebp  ; Unix ABI says to do this.
  ; TODO?: Unix ABI says rdx is a function pointer to register with atexit.

  mov ebx, amount_threads

.loop:
  sub ebx, 1
  jz .done

  ; Get space for the threads' stacks, via mmap.
  xor r9d, r9d              ; pgoffset
  mov r8, dword -1          ; fd
  mov r10d, 0x20022         ; flags = MAP_PRIVATE | MAP_ANONYMOUS | MAP_STACK
  mov edx, 3                ; prot = PROT_READ | PROT_WRITE
  mov esi, call_stack_size  ; length
  xor edi, edi              ; addr = NULL
  mov eax, 9                ; mmap syscall number
  syscall
  cmp rax, -4096
  ja .mmap_failed

  ; Create the threads using clone.
  xor r8d, r8d         ; tls = NULL
  xor r10d, r10d       ; ctid = NULL
  xor edx, edx         ; ptid = NULL
  add rax, call_stack_size
  mov rsi, rax         ; child_stack = end of mmap'ed memory
  mov edi, 0x80012F00  ; flags = CLONE_FILES | CLONE_FS | CLONE_IO | CLONE_PTRACE
                       ;         | CLONE_SIGHAND | CLONE_THREAD | CLONE_VM
  mov eax, 56          ; clone syscall number
  syscall
  cmp rax, -4096
  ja .clone_failed

  test rax, rax
  jnz .loop  ; Caller of clone jumps.  New threads don't.

.done:
  ; Set the threads' ID-offset register.
  ; Set bit 32 for indicating needyness.
  mov needy_tid_r15, 1 << 32
  ; Multiply thread ID by 128: the offset of a thread's variables.
  shl ebx, 7
  or needy_tid_r15, rbx
  ; Begin executing the user's program.
  test ebx, ebx
  jz main  ; Initial thread, thread 0, does this.
  jmp exec_avail  ; Other threads do this.  TODO?: Delay a bit first?

.mmap_failed:
  ; TODO: Negated error code is in rax, print to stderr, and do something...
  jmp bug

.clone_failed:
  ; TODO: Negated error code is in rax, print to stderr, and do something...
  jmp bug




%ifdef statistics_collection

proc print_stats:
  ; Print collected statistics for each thread, and print the totals of all
  ; threads.  Called directly via call not via exec_avail, so the things having
  ; statistics collected are not used to execute it.

  ; Temporary struc for the totals of all threads.
  sub rsp, stats_size
  ; [rsp + stats.exec_s_max] not totaled.
  ; [rsp + stats.exec_s_size] not totaled.
  mov qword [rsp + stats.execute_calls], 0
  mov qword [rsp + stats.executed_mine], 0
  mov qword [rsp + stats.needy], 0
  mov qword [rsp + stats.sched_calls], 0
  mov qword [rsp + stats.sched_mine], 0
  ; [rsp + stats.alloc_s_max] not totaled.
  ; [rsp + stats.alloc_s_size] not totaled.
  mov qword [rsp + stats.allocated], 0
  mov qword [rsp + stats.alloc_orphans], 0
  mov qword [rsp + stats.freed], 0
  mov qword [rsp + stats.freed_orphans], 0
  ; [rsp + stats.used_max] not totaled.
  ; [rsp + stats.in_use] not totaled.
  mov qword [rsp + stats.mmap], 0

  mov ebx, amount_threads - 1
.loop:
  mov esi, ebx
  mov edi, stats_tid_fmtstr
  mov eax, 0
  call printf
  ; Multiply thread ID by 128: the offset of the thread's stats address.
  shl ebx, 7

  mov rsi, [statistics + ebx + stats.exec_s_max]
  mov edi, stats_exec_s_max_fmtstr
  mov eax, 0
  call printf

  mov rsi, [statistics + ebx + stats.exec_s_size]
  mov edi, stats_exec_s_size_fmtstr
  mov eax, 0
  call printf

  mov rsi, [statistics + ebx + stats.execute_calls]
  add [rsp + stats.execute_calls], rsi
  mov edi, stats_execute_calls_fmtstr
  mov eax, 0
  call printf

  mov rsi, [statistics + ebx + stats.executed_mine]
  add [rsp + stats.executed_mine], rsi
  mov edi, stats_executed_mine_fmtstr
  mov eax, 0
  call printf

  mov rsi, [statistics + ebx + stats.needy]
  add [rsp + stats.needy], rsi
  mov edi, stats_needy_fmtstr
  mov eax, 0
  call printf

  mov rsi, [statistics + ebx + stats.sched_calls]
  add [rsp + stats.sched_calls], rsi
  mov edi, stats_sched_calls_fmtstr
  mov eax, 0
  call printf

  mov rsi, [statistics + ebx + stats.sched_mine]
  add [rsp + stats.sched_mine], rsi
  mov edi, stats_sched_mine_fmtstr
  mov eax, 0
  call printf

  mov rsi, [statistics + ebx + stats.alloc_s_max]
  mov edi, stats_alloc_s_max_fmtstr
  mov eax, 0
  call printf

  mov rsi, [statistics + ebx + stats.alloc_s_size]
  mov edi, stats_alloc_s_size_fmtstr
  mov eax, 0
  call printf

  mov rsi, [statistics + ebx + stats.allocated]
  add [rsp + stats.allocated], rsi
  mov edi, stats_allocated_fmtstr
  mov eax, 0
  call printf

  mov rsi, [statistics + ebx + stats.alloc_orphans]
  add [rsp + stats.alloc_orphans], rsi
  mov edi, stats_alloc_orphans_fmtstr
  mov eax, 0
  call printf

  mov rsi, [statistics + ebx + stats.freed]
  add [rsp + stats.freed], rsi
  mov edi, stats_freed_fmtstr
  mov eax, 0
  call printf

  mov rsi, [statistics + ebx + stats.freed_orphans]
  add [rsp + stats.freed_orphans], rsi
  mov edi, stats_freed_orphans_fmtstr
  mov eax, 0
  call printf

  mov rsi, [statistics + ebx + stats.mmap]
  add [rsp + stats.mmap], rsi
  mov edi, stats_mmap_fmtstr
  mov eax, 0
  call printf

  mov eax, mmap_tasks * task_size / 1024
  mov rsi, [statistics + ebx + stats.mmap]
  mul rsi
  mov rsi, rdx
  mov rdx, rax
  mov edi, stats_mmap_kb_fmtstr
  mov eax, 0
  call printf

  shr ebx, 7
  sub ebx, 1
  jnc .loop

  mov esi, amount_threads
  mov edi, stats_total_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + stats.execute_calls]
  mov edi, stats_execute_calls_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + stats.executed_mine]
  mov edi, stats_executed_mine_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + stats.needy]
  mov edi, stats_needy_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + stats.sched_calls]
  mov edi, stats_sched_calls_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + stats.sched_mine]
  mov edi, stats_sched_mine_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + stats.allocated]
  mov edi, stats_allocated_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + stats.alloc_orphans]
  mov edi, stats_alloc_orphans_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + stats.freed]
  mov edi, stats_freed_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + stats.freed_orphans]
  mov edi, stats_freed_orphans_fmtstr
  mov eax, 0
  call printf

  mov rsi, [statistics + 0 + stats.used_max]
  mov edi, stats_used_max_fmtstr
  mov eax, 0
  call printf

  mov rsi, [statistics + 0 + stats.in_use]
  mov edi, stats_in_use_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + stats.mmap]
  mov edi, stats_mmap_fmtstr
  mov eax, 0
  call printf

  mov eax, mmap_tasks * task_size / 1024
  mov rsi, [rsp + stats.mmap]
  mul rsi
  mov rsi, rdx
  mov rdx, rax
  mov edi, stats_mmap_kb_fmtstr
  mov eax, 0
  call printf

  add rsp, stats_size
  ret

%endif




section .data  align=128

; Variables and strucs are aligned at 128-byte boundary because this improves
; cache-coherency performance, and because this improves the performance of
; processor bus locking used for atomic operations.  It also makes the needed
; 8-byte alignment for atomic field access.


; Threads' private executable-tasks stacks.

executables:

%assign n 0
%rep amount_threads

executables_%[n]:
dq 0
align 128, db 0

%assign n  n + 1
%endrep




; Threads' private allocatable-tasks stacks.

allocatables:

%assign n 0
%rep amount_threads

allocatables_%[n]:
dq allocatables_%[n]_head
align 128, db 0

%assign n  n + 1
%endrep




; The global variable for indicating what thread needs a task.

needy:
dq 0
align 128, db 0




; Threads' variables for receiving executable tasks given from other threads.

gifts:

%assign n 0
%rep amount_threads

gifts_%[n]:
dq 0
align 128, db 0

%assign n  n + 1
%endrep




; Threads' stacks for other threads to free strucs to each other.

orphans:

%assign n 0
%rep amount_threads

orphans_%[n]:
dq 0
align 128, db 0

%assign n  n + 1
%endrep




; Statically-allocated and initialized task strucs for the allocatable-tasks
; stacks.  Task strucs are 128-bytes long, which preserves their 128-byte
; alignment when they are contiguously located like below.

%assign n 0
%rep amount_threads

allocatables_%[n]_head:

  istruc task
    at task.next,    dq allocatables_%[n]_1
    at task.owner,   dq n << 7
    at task.rcvr,    dq 0
    at task.ridx,    dq 0
    at task.need,    dq 0
    at task.exec,    dq 0
    at task.arg1,    dq 0
    at task.arg2,    dq 0
    at task.arg3,    dq 0
    at task.arg4,    dq 0
    at task.arg5,    dq 0
    at task.arg6,    dq 0
    at task.arg7,    dq 0
    at task.arg8,    dq 0
    at task.arg9,    dq 0
    at task.arg10,   dq 0
  iend


allocatables_%[n]_1:

%assign a 2
%rep statically_allocated_free_tasks - 2

  istruc task
    at task.next,    dq allocatables_%[n]_%[a]
    at task.owner,   dq n << 7
    at task.rcvr,    dq 0
    at task.ridx,    dq 0
    at task.need,    dq 0
    at task.exec,    dq 0
    at task.arg1,    dq 0
    at task.arg2,    dq 0
    at task.arg3,    dq 0
    at task.arg4,    dq 0
    at task.arg5,    dq 0
    at task.arg6,    dq 0
    at task.arg7,    dq 0
    at task.arg8,    dq 0
    at task.arg9,    dq 0
    at task.arg10,   dq 0
  iend

allocatables_%[n]_%[a]:

%assign a  a + 1
%endrep


  istruc task
    at task.next,    dq 0
    at task.owner,   dq n << 7
    at task.rcvr,    dq 0
    at task.ridx,    dq 0
    at task.need,    dq 0
    at task.exec,    dq 0
    at task.arg1,    dq 0
    at task.arg2,    dq 0
    at task.arg3,    dq 0
    at task.arg4,    dq 0
    at task.arg5,    dq 0
    at task.arg6,    dq 0
    at task.arg7,    dq 0
    at task.arg8,    dq 0
    at task.arg9,    dq 0
    at task.arg10,   dq 0
  iend

%assign n  n + 1
%endrep




%ifdef statistics_collection

statistics:

%rep amount_threads

  istruc stats
    at stats.exec_s_max,     dq 0
    at stats.exec_s_size,    dq 0
    at stats.execute_calls,  dq 0
    at stats.executed_mine,  dq 0
    at stats.needy,          dq 0
    at stats.sched_calls,    dq 0
    at stats.sched_mine,     dq 0
    at stats.alloc_s_max,    dq statically_allocated_free_tasks
    at stats.alloc_s_size,   dq statically_allocated_free_tasks
    at stats.allocated,      dq 0
    at stats.alloc_orphans,  dq 0
    at stats.freed,          dq 0
    at stats.freed_orphans,  dq 0
    at stats.used_max,       dq 0
    at stats.in_use,         dq 0
    at stats.mmap,           dq 0
  iend

align 128, db 0  ; Necessary because the exec and alloc stacks are used to find
                 ; each thread's stats struc.
%endrep

stats_tid_fmtstr:            db `Thread %lu:\n`,0
stats_exec_s_max_fmtstr:     db `  exec_s max:    %15llu\n`,0
stats_exec_s_size_fmtstr:    db `  exec_s size:   %15llu\n`,0
stats_execute_calls_fmtstr:  db `  execute calls: %15llu\n`,0
stats_executed_mine_fmtstr:  db `  executed mine: %15llu\n`,0
stats_needy_fmtstr:          db `  needy:         %15llu\n`,0
stats_sched_calls_fmtstr:    db `  sched calls:   %15llu\n`,0
stats_sched_mine_fmtstr:     db `  sched mine:    %15llu\n`,0
stats_alloc_s_max_fmtstr:    db `  alloc_s max:   %15llu\n`,0
stats_alloc_s_size_fmtstr:   db `  alloc_s size:  %15llu\n`,0
stats_allocated_fmtstr:      db `  allocated:     %15llu\n`,0
stats_alloc_orphans_fmtstr:  db `  alloc orphans: %15llu\n`,0
stats_freed_fmtstr:          db `  freed:         %15llu\n`,0
stats_freed_orphans_fmtstr:  db `  freed orphans: %15llu\n`,0
stats_used_max_fmtstr:       db `  used max:      %15llu\n`,0
stats_in_use_fmtstr:         db `  in use:        %15llu\n`,0
stats_mmap_fmtstr:           db `  mmaps:         %15llu\n`,0
stats_mmap_kb_fmtstr:        db `  KB mmaped:     %llu,%llu\n`,0
stats_total_fmtstr:          db `Totals of %lu threads:\n`,0

%endif
