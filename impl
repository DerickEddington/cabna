bits 64
default rel


global _start
global alloc_task
global enqueue_task
global supply_retval
global exec_avail
global free_pet__exec_avail

extern main
extern bug


%include "cabna/conv"


; It is assumed that all Cabna code and data is located in 32-bit address space,
; which allows assuming Cabna addresses fit in 32 bits.  This is taken advantage
; of to use 32-bit operations instead of 64-bit, as the processor manufacturers
; recommend, when possible, for optimization, and also to fit two pointers in
; r15.  Cabna is still a 64-bit system intended for 64-bit use, and 64-bit
; addresses and operations are used for users' stuff and strucs that might be
; allocated in 64-bit space.


; Users' responsibilities:
;  1) Task strucs must not be in more than one queue at a time.
;  2) Task strucs must not be in the same queue more than once.
;  3) The memory allocated by the OS for task strucs must never be returned to
;     the OS.
; It is assumed that users obey these responsibilities.




section .text


proc alloc_task:
  ; Dequeue a free task struc, from the current thread's allocatable-tasks
  ; queue, or allocate more memory from the OS, and return to ret_rsi with task
  ; pointer in arg1_rdi.  Each thread has its own private allocatable-tasks
  ; queue, so concurrency-safety is not needed.
  ; Used registers: rax, rcx, rdx, rsi, rdi, r8, r9, r10, r11.

  mov arg1_rdi, [alloc_q_r15d + queue.head]
  test arg1_rdi, arg1_rdi
  unlikely jz .get_new_space
  ; The next becomes the head, which might be null.
  mov rax, [arg1_rdi + task.next]
  mov [alloc_q_r15d + queue.head], rax
  test rax, rax
  jz .also_tail
  mov qword [arg1_rdi + task.next], 0
  jmp_ind ret_rsi

.also_tail:
  ; If the next is null, our struc was also the tail, so nullify queue's tail.
  mov [alloc_q_r15d + queue.tail], rax
  jmp_ind ret_rsi

.get_new_space:
  ; Get some more space from the OS, divide it into blocks of task strucs, link
  ; them together, and enqueue all-at-once.  The fields of the new strucs are
  ; null because mmap zeros, as needed for future operations.

  ; Save registers.
  ;mov ?, r9
  ;mov ?, r8
  ;mov ?, r10
  ;mov ?, rdx
  mov [alloc_q_r15d + queue.head], ret_rsi  ; Just a temporary location.
  ;mov ?, rdi
  ;mov ?, rax  ; syscall destroys
  ;mov ?, rcx  ; syscall destroys
  ;mov ?, r11  ; syscall destroys

  ; mmap a space.
  xor r9d, r9d                     ; pgoffset
  mov r8, dword -1                 ; fd
  mov r10d, 0x22                   ; flags = MAP_PRIVATE | MAP_ANONYMOUS
  mov edx, 3                       ; prot = PROT_READ | PROT_WRITE
  mov esi, mmap_tasks * task_size  ; length
  xor edi, edi                     ; addr = NULL
  mov eax, 9                       ; mmap syscall number
  syscall
  cmp rax, -4096
  ja .mmap_failed

  ; Reserve first block for return value.
  mov arg1_rdi, rax
  ; Divide remaining space into task strucs, and link together.
  add rax, rsi  ; End of the space.
  sub rax, task_size  ; Tail struc is the last block.
  mov [alloc_q_r15d + queue.tail], rax
.divide_and_link:
  mov rdx, rax
  sub rax, task_size
  cmp rax, arg1_rdi
  jbe .done
  mov [rax + task.next], rdx
  jmp .divide_and_link
.done:
  mov ret_rsi, [alloc_q_r15d + queue.head]  ; Restore saved.
  mov [alloc_q_r15d + queue.head], rdx
  jmp_ind ret_rsi  ; Return first block of new space.

.mmap_failed:
  ; TODO: Negated error code is in rax, print to stderr, and do something...
  jmp bug




proc supply_retval:
  ; Return a value to a waiting receiver task, argument in arg1_rdi.  If the
  ; receiver task gets its final value, enqueue the task for execution.  Return
  ; to ret_rsi.
  ; Used registers: rax, rdx, rsi, rdi.

  ; No other threads will access our currently executing task struc, so we can
  ; access it without concurrency concern.
  mov rax, [cet_r14 + task.rcvr]
  mov edx, [cet_r14 + task.ridx]  ; 32-bit alright.
  ; No other threads will access this field in rcvr, so we can access it without
  ; concurrency concern.
  mov [rax + task.args + 8 * rdx], arg1_rdi
  ; Other threads will access the .need field, so we must atomically decrement
  ; it.
  lock sub dword [rax + task.need], 1  ; 32-bit alright.
  cmovz arg1_rdi, rax  ; For enqueue_task.
  ; Supplied the final needed argument to rcvr, so enqueue rcvr for execution.
  jz enqueue_task  ; ret_rsi already set.
  ; Receiver needs more.
  jmp_ind ret_rsi




proc enqueue_task:
  ; Enqueue a task in the current thread's executable-tasks queue, or another
  ; thread's, argument in arg1_rdi, and return to ret_rsi.
  ; Used registers: rax, rdx, rsi, rdi.

  mov rdx, exec_q_r15
  shr rdx, 32
.try:
  bt dword [edx + queue.next], 0
  jc .another  ; Another thread already has it locked.
  ; Try to lock the queue for our use.
  lock bts dword [edx + queue.next], 0
  unlikely jc .another  ; Another thread just locked it.

  ; Other threads cannot concurrently execute the rest of this procedure, for
  ; the same queue.  This is what enables the concurrency-safety.

  mov rax, [edx + queue.tail]
  test rax, rax
  jz .empty
  mov [rax + task.next], arg1_rdi
.done:
  mov [edx + queue.tail], arg1_rdi
  ; Unlock the queue.
  and dword [edx + queue.next], -2  ; Clear lock bit.
  jmp_ind ret_rsi

.another:
  ; Try to enqueue the task in another thread's queue.
  mov edx, [edx + queue.next]
  and edx, -2  ; Clear possibly-set lock bit.
  jmp .try

.empty:
  mov [edx + queue.head], arg1_rdi
  jmp .done




proc free_pet__exec_avail:
  ; Free the previously executing task by enqueueing it in the current thread's
  ; allocatable-tasks queue, and continue into exec_avail.  Each thread has its
  ; own private allocatable-tasks queue, so concurrency-safety is not needed.
  ; Used registers: rax, and those of exec_avail.

  mov rax, [alloc_q_r15d + queue.tail]
  test rax, rax
  jz .empty
  mov [rax + task.next], cet_r14
.done:
  mov [alloc_q_r15d + queue.tail], cet_r14
  jmp exec_avail

.empty:
  mov [alloc_q_r15d + queue.head], cet_r14
  jmp .done




proc exec_avail:
  ; Dequeue the oldest task from the current thread's executable-tasks queue, or
  ; from another thread's, and execute the task with cet_r14 set to the task.
  ; Used registers: rax, rdx, r14

  mov rdx, exec_q_r15
  shr rdx, 32
.try:
  bt dword [edx + queue.next], 0
  jc .another  ; Another thread already has it locked.
  ; Try to lock the queue for our use.
  lock bts dword [edx + queue.next], 0
  unlikely jc .another  ; Another thread just locked it.

  ; Other threads cannot concurrently execute the rest of this procedure, for
  ; the same queue.  This is what enables the concurrency-safety.

  mov cet_r14, [edx + queue.head]
  test cet_r14, cet_r14
  jz .another_unlock
  ; The next becomes the head, which might be null.
  mov rax, [cet_r14 + task.next]
  mov [edx + queue.head], rax
  test rax, rax
  jz .also_tail
  mov qword [cet_r14 + task.next], 0
.done:
  ; Unlock the queue.
  and dword [edx + queue.next], -2  ; Clear lock bit.
  ; Execute the task's instructions.  Tasks are responsibile for giving control
  ; back to exec_evail.
  jmp_ind [cet_r14 + task.exec]

.another_unlock:
  ; Unlock the empty queue.
  and dword [edx + queue.next], -2  ; Clear lock bit.
.another:
  ; Try to take a task from another thread.
  mov edx, [edx + queue.next]
  and edx, -2  ; Clear possibly-set lock bit.
  jmp .try

.also_tail:
  ; If the next is null, our struc was also the tail, so nullify queue's tail.
  mov [edx + queue.tail], rax
  jmp .done



; Entry point.
; TODO: This will need to change for multiple threads.
proc _start:
  ; Set the threads' executable-tasks and allocatable-tasks queues register.
  mov r15d, t0_exec_q  ; Assumes it's in 32-bit space.
  shl r15, 32          ; It lives in the high 32 bits.
  mov eax, t0_alloc_q  ; Assumes it's in 32-bit space.
  or r15, rax          ; It lives in the low 32 bits.
  jmp main




section .data  align=128

; Strucs are aligned at 128-byte boundary because this makes the processor bus
; locking used for atomic operations more efficient.  It also makes the needed
; 8-byte alignment for atomic field access.


; Threads' executable-tasks queues.

%assign n 0
%rep amount_threads

align 128, db 0

t%[n]_exec_q:

%assign n  (n + 1) % amount_threads  ; Last's .next = first.

  istruc queue
    at queue.next, dq t%[n]_exec_q  ; Lock bit not set.
    at queue.head, dq 0
    at queue.tail, dq 0
  iend
%endrep




; Threads' allocatable-tasks queues.

%assign n 0
%rep amount_threads

align 128, db 0  ; Actually not necessary, because these aren't locked.

t%[n]_alloc_q:

  istruc queue
    at queue.next, dq 0  ; Never used.
    at queue.head, dq t%[n]_alloc_q_head
    at queue.tail, dq t%[n]_alloc_q_tail
  iend

%assign n  n + 1
%endrep




; Statically-allocated and initialized task strucs for the allocatable-tasks
; queues.

align 128, db 0

; Task strucs are 128-bytes long, which preserves their 128-byte alignment when
; they are contiguously located like below.

%assign n 0
%rep amount_threads

t%[n]_alloc_q_head:

  istruc task
    at task.next,    dq t%[n]_alloc_q_1
    at task.rcvr,    dq 0
    at task.ridx,    dq 0
    at task.need,    dq 0
    at task.exec,    dq 0
    at task.arg1,    dq 0
    at task.arg2,    dq 0
    at task.arg3,    dq 0
    at task.arg4,    dq 0
    at task.arg5,    dq 0
    at task.arg6,    dq 0
    at task.arg7,    dq 0
    at task.arg8,    dq 0
    at task.arg9,    dq 0
    at task.arg10,   dq 0
    at task.arg11,   dq 0
  iend


t%[n]_alloc_q_1:

%assign a 2
%rep statically_allocated_free_tasks - 2

  istruc task
    at task.next,    dq t%[n]_alloc_q_%[a]
    at task.rcvr,    dq 0
    at task.ridx,    dq 0
    at task.need,    dq 0
    at task.exec,    dq 0
    at task.arg1,    dq 0
    at task.arg2,    dq 0
    at task.arg3,    dq 0
    at task.arg4,    dq 0
    at task.arg5,    dq 0
    at task.arg6,    dq 0
    at task.arg7,    dq 0
    at task.arg8,    dq 0
    at task.arg9,    dq 0
    at task.arg10,   dq 0
    at task.arg11,   dq 0
  iend

t%[n]_alloc_q_%[a]:

%assign a  a + 1
%endrep


t%[n]_alloc_q_tail:

  istruc task
    at task.next,    dq 0
    at task.rcvr,    dq 0
    at task.ridx,    dq 0
    at task.need,    dq 0
    at task.exec,    dq 0
    at task.arg1,    dq 0
    at task.arg2,    dq 0
    at task.arg3,    dq 0
    at task.arg4,    dq 0
    at task.arg5,    dq 0
    at task.arg6,    dq 0
    at task.arg7,    dq 0
    at task.arg8,    dq 0
    at task.arg9,    dq 0
    at task.arg10,   dq 0
    at task.arg11,   dq 0
  iend

%assign n  n + 1
%endrep
