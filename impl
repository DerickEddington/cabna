bits 64
default rel


%include "cabna/conv"


global _start
global alloc_task
global sched_task
global notify_receiver
global supply_retval
global exec_avail
global free_pet__exec_avail
global main_semaphore

%ifdef statistics_collection
global print_stats
extern printf
%endif

extern main
extern bug


; It is assumed that all Cabna code and data is located in 32-bit address space,
; which allows assuming Cabna addresses fit in 32 bits.  This is taken advantage
; of to use 32-bit operations instead of 64-bit, as the processor manufacturers
; recommend, when possible, for optimization, and also to fit two values in r15.
; Cabna is still a 64-bit system intended for 64-bit use, and 64-bit addresses
; and operations are used for users' stuff and strucs that might be allocated in
; 64-bit space.


; Users' responsibilities:
;  1) Task strucs must not be in more than one stack at a time.
;  2) Task strucs must not be in the same stack more than once.
;  3) The memory allocated by the OS for task strucs must never be returned to
;     the OS.
; It is assumed that users obey these responsibilities.




section .text


proc alloc_task:
  ; Pop a free task struc from the thread's private allocatable-tasks stack, or
  ; see if other threads have freed any of the thread's strucs, or allocate more
  ; memory from the OS, and return to ret_rsi with task pointer in arg1_rdi.
  ; Used registers: rax, rcx, rdx, rsi, rdi, r8, r9, r10, r11.

%ifdef statistics_collection
  add qword [tds_r15d + thread.allocate_calls], 1
  mov ecx, 1
  lock xadd [in_use], rcx
  add rcx, 1
  mov rax, [used_max]
.retry_max:
  cmp rcx, rax
  jbe .not_used_max
  lock cmpxchg [used_max], rcx
  jne .retry_max
.not_used_max:
%endif

  mov arg1_rdi, [tds_r15d + thread.allocatables]
  test arg1_rdi, arg1_rdi
  jz .orphans

.done:
  ; The next, which might be null, becomes the head.
  mov rax, [arg1_rdi + task.next]
  mov [tds_r15d + thread.allocatables], rax
  mov qword [arg1_rdi + task.next], 0
  stat sub qword [tds_r15d + thread.alloc_s_size], 1
  jmp_ind ret_rsi

.orphans:
  mov rax, [tds_r15d + thread.orphans]
  test rax, rax
  jz .get_new_space
  ; The field will still be non-null if another thread changes it.
  ; arg1_rdi already null.
  xchg [tds_r15d + thread.orphans], arg1_rdi  ; Locking automatically done for xchg.
%ifdef statistics_collection
  mov rax, arg1_rdi
  xor ecx, ecx
.orphans_size:
  add rcx, 1
  mov rax, [rax + task.next]
  test rax, rax
  jnz .orphans_size
  mov [tds_r15d + thread.alloc_s_size], rcx
  cmp rcx, [tds_r15d + thread.alloc_s_max]
  jbe .not_alloc_s_max
  mov [tds_r15d + thread.alloc_s_max], rcx
.not_alloc_s_max:
  add qword [tds_r15d + thread.alloc_orphans], 1
%endif
  jmp .done

.get_new_space:
  ; Get some more space from the OS, divide into blocks of task strucs, link
  ; together, push-at-once, and return a struc.  The unset fields of the new
  ; strucs are null because mmap zeros, as needed for future operations.

  ; Save registers.
  ;mov ?, r9
  ;mov ?, r8
  ;mov ?, r10
  ;mov ?, rdx
  mov [tds_r15d + thread.allocatables], ret_rsi  ; Just a temporary location.
  ;mov ?, rdi
  ;mov ?, rax  ; syscall destroys
  ;mov ?, rcx  ; syscall destroys
  ;mov ?, r11  ; syscall destroys

  ; mmap a space.
  xor r9d, r9d                     ; pgoffset
  mov r8, dword -1                 ; fd
  mov r10d, 0x22                   ; flags = MAP_PRIVATE | MAP_ANONYMOUS
  mov edx, 3                       ; prot = PROT_READ | PROT_WRITE
  mov esi, mmap_tasks * task_size  ; length
  xor edi, edi                     ; addr = NULL
  mov eax, 9                       ; mmap syscall number
  syscall
  cmp rax, -4096
  ja .mmap_failed

  ; Reserve first struc for return value.
  mov arg1_rdi, rax
  mov [rax + task.owner], tds_r15d
  ; Divide remaining space into task strucs, and link together.
  add rax, rsi  ; End of the space.
  sub rax, task_size  ; Tail struc is the last block.
  xor edx, edx
.divide_and_link:
  mov [rax + task.owner], tds_r15d
  mov [rax + task.next], rdx
  mov rdx, rax
  sub rax, task_size
  cmp rax, arg1_rdi
  ja .divide_and_link
  mov ret_rsi, [tds_r15d + thread.allocatables]  ; Restore saved.
  mov [tds_r15d + thread.allocatables], rdx
%ifdef statistics_collection
  mov eax, mmap_tasks - 1
  mov [tds_r15d + thread.alloc_s_size], rax
  cmp rax, [tds_r15d + thread.alloc_s_max]
  jbe .not_alloc_s_max_2
  mov [tds_r15d + thread.alloc_s_max], rax
.not_alloc_s_max_2:
  add qword [tds_r15d + thread.mmap], 1
%endif
  jmp_ind ret_rsi

.mmap_failed:
  ; TODO: Negated error code is in rax, print to stderr, and do something...
  jmp bug




proc notify_receiver:
  ; Notify the currently executing task's waiting receiver task that one of its
  ; tasks finished.  If the receiver task gets its final notice, schedule the
  ; task for execution.  Return to ret_rsi.
  ; Used registers: rsi, rdi.

  ; No other threads will access our currently executing task struc, so we can
  ; access it without concurrency concern.
  mov rdi, [cet_r14 + task.rcvr]
  ; Other threads will access the .need field, so we must atomically decrement
  ; it.
  lock sub dword [rdi + task.need], 1  ; 32-bit alright.
  ; Supplied the final needed argument to rcvr, so schedule rcvr for execution.
  jz sched_task  ; arg1_rdi and ret_rsi are already set.
  ; Receiver needs more.
  jmp_ind ret_rsi




proc supply_retval:
  ; Return a value to the currently executing task's waiting receiver task,
  ; argument in arg1_rdi.  If the receiver task gets its final value, schedule
  ; the task for execution.  Return to ret_rsi.
  ; Used registers: rax, rdx, rsi, rdi.

  ; No other threads will access our currently executing task struc, so we can
  ; access it without concurrency concern.
  mov rax, [cet_r14 + task.rcvr]
  mov edx, [cet_r14 + task.ridx]  ; 32-bit alright.
  ; No other threads will access this field in rcvr, so we can access it without
  ; concurrency concern.
  mov [rax + task.args + 8 * rdx], arg1_rdi
  ; Other threads will access the .need field, so we must atomically decrement
  ; it.
  lock sub dword [rax + task.need], 1  ; 32-bit alright.
  cmovz arg1_rdi, rax  ; For sched_task.
  ; Supplied the final needed argument to rcvr, so schedule rcvr for execution.
  jz sched_task  ; ret_rsi already set.
  ; Receiver needs more.
  jmp_ind ret_rsi




proc sched_task:
  ; Push a task in the thread's private executable-tasks stack, or if the stack
  ; already has at least one task and another thread needs a task, try to give
  ; the task to the needy thread.  Argument in arg1_rdi, and return to ret_rsi.
  ; Used registers: rax, rdx, rsi, rdi.

  stat add qword [tds_r15d + thread.sched_calls], 1

  mov rax, [tds_r15d + thread.executables]
  test rax, rax
  jz .in_mine_empty

  ; Check if another thread needs a task.
  mov edx, [needy]
  test edx, edx
  jnz .give

.in_mine:
  mov [arg1_rdi + task.next], rax
.in_mine_empty:
  mov [tds_r15d + thread.executables], arg1_rdi
%ifdef statistics_collection
  add qword [tds_r15d + thread.sched_mine], 1
  mov rax, [tds_r15d + thread.exec_s_size]
  add rax, 1
  mov [tds_r15d + thread.exec_s_size], rax
  cmp rax, [tds_r15d + thread.exec_s_max]
  jbe .not_max
  mov [tds_r15d + thread.exec_s_max], rax
.not_max:
%endif
  jmp_ind ret_rsi

.give:
  xor edx, edx
  xchg [needy], edx  ; Locking automatically done for xchg.
  test edx, edx
  unlikely jz .in_mine
  mov [edx + thread.gift], arg1_rdi
  jmp_ind ret_rsi




proc free_pet__exec_avail:
  ; Free the previously executing task by pushing it in the thread's private
  ; allocatable-tasks stack; or if the struc belongs to another thread, give it
  ; to the owner; and continue into exec_avail.
  ; Used registers: rax, rdx, and those of exec_avail.

  stat lock sub qword [in_use], 1
  stat add qword [tds_r15d + thread.freed], 1

  mov edx, [cet_r14 + task.owner]
  cmp edx, tds_r15d
  jne .orphan

  mov rax, [tds_r15d + thread.allocatables]
  mov [cet_r14 + task.next], rax
  mov [tds_r15d + thread.allocatables], cet_r14

%ifdef statistics_collection
  mov rax, [tds_r15d + thread.alloc_s_size]
  add rax, 1
  mov [tds_r15d + thread.alloc_s_size], rax
  cmp rax, [tds_r15d + thread.alloc_s_max]
  jbe .not_max
  mov [tds_r15d + thread.alloc_s_max], rax
.not_max:
%endif

  jmp exec_avail

.orphan:
  mov rax, [edx + thread.orphans]
.retry:
  ; pause  ; Not needed, I think, because the lock cmpxchg is always done.
  mov [cet_r14 + task.next], rax
  lock cmpxchg [edx + thread.orphans], cet_r14
  jne .retry
  stat add qword [tds_r15d + thread.freed_orphans], 1
  jmp exec_avail




proc exec_avail:
  ; Pop a task from the thread's private executable-tasks stack, or indicate
  ; that the thread needs a task and wait for one, then execute the task with
  ; cet_r14 set to the task.
  ; Used registers: rax, r14.

  stat add qword [tds_r15d + thread.execute_calls], 1

  mov cet_r14, [tds_r15d + thread.executables]
  test cet_r14, cet_r14
  jz .empty

  ; The next, which might be null, becomes the head.
  mov rax, [cet_r14 + task.next]
  mov [tds_r15d + thread.executables], rax
  mov qword [cet_r14 + task.next], 0

  stat sub qword [tds_r15d + thread.exec_s_size], 1
  stat add qword [tds_r15d + thread.executed_mine], 1

  ; Execute the task's instructions.  Tasks are responsible for giving control
  ; back to exec_evail.
  jmp_ind [cet_r14 + task.exec]

.empty:
  pause
  mov eax, [needy]
  test eax, eax
  unlikely jnz .empty
  lock cmpxchg [needy], tds_r15d
  unlikely jne .empty
.wait:
  pause
  mov cet_r14, [tds_r15d + thread.gift]
  test cet_r14, cet_r14
  jz .wait
  mov [tds_r15d + thread.gift], rax  ; rax is null.
  stat add qword [tds_r15d + thread.needy], 1
  ; Execute the task's instructions.  Tasks are responsible for giving control
  ; back to exec_evail.
  jmp_ind [cet_r14 + task.exec]




proc _start:
  ; Entry point.

  xor ebp, ebp  ; Unix ABI says to do this.
  ; TODO?: Unix ABI says rdx is a function pointer to register with atexit.

  mov ebx, amount_threads

.loop:
  sub ebx, 1
  jz .done

  ; Get space for the threads' stacks, via mmap.
  xor r9d, r9d              ; pgoffset
  mov r8, dword -1          ; fd
  mov r10d, 0x20022         ; flags = MAP_PRIVATE | MAP_ANONYMOUS | MAP_STACK
  mov edx, 3                ; prot = PROT_READ | PROT_WRITE
  mov esi, call_stack_size  ; length
  xor edi, edi              ; addr = NULL
  mov eax, 9                ; mmap syscall number
  syscall
  cmp rax, -4096
  ja .mmap_failed

  ; Create the threads using clone.
  xor r8d, r8d         ; tls = NULL
  xor r10d, r10d       ; ctid = NULL
  xor edx, edx         ; ptid = NULL
  add rax, call_stack_size
  mov rsi, rax         ; child_stack = end of mmap'ed memory
  mov edi, 0x80012F00  ; flags = CLONE_FILES | CLONE_FS | CLONE_IO | CLONE_PTRACE
                       ;         | CLONE_SIGHAND | CLONE_THREAD | CLONE_VM
  mov eax, 56          ; clone syscall number
  syscall
  cmp rax, -4096
  ja .clone_failed

  test rax, rax
  jnz .loop  ; Caller of clone jumps.  New threads don't.

.done:
  ; Set the threads' data struc register.
  mov eax, thread_0_end - thread_0
  mul ebx
  jc .too_many_threads
  add eax, threads
  jc .too_many_threads
  mov tds_r15d, eax
  ; Begin executing the user's program.
  mov edi, ebx  ; Thread ID is the argument to main.
  jmp main
  ; TODO?: Call main and after do exit syscall?

.mmap_failed:
  ; TODO: Negated error code is in rax, print to stderr, and do something...
  jmp bug

.clone_failed:
  ; TODO: Negated error code is in rax, print to stderr, and do something...
  jmp bug

.too_many_threads:
  ; TODO: Print something to stderr...
  jmp bug




%ifdef statistics_collection

proc print_stats:
  ; Print collected statistics for each thread, and print the totals of all
  ; threads.  Called directly via call not via exec_avail, so the things having
  ; statistics collected are not used to execute it.

  ; Temporary struc for the totals of all threads.
  sub rsp, thread_size
  ; [rsp + thread.exec_s_max] not totaled.
  ; [rsp + thread.exec_s_size] not totaled.
  mov qword [rsp + thread.execute_calls], 0
  mov qword [rsp + thread.executed_mine], 0
  mov qword [rsp + thread.needy], 0
  mov qword [rsp + thread.sched_calls], 0
  mov qword [rsp + thread.sched_mine], 0
  ; [rsp + thread.alloc_s_max] not totaled.
  ; [rsp + thread.alloc_s_size] not totaled.
  mov qword [rsp + thread.allocate_calls], 0
  mov qword [rsp + thread.alloc_orphans], 0
  mov qword [rsp + thread.freed], 0
  mov qword [rsp + thread.freed_orphans], 0
  mov qword [rsp + thread.mmap], 0

  mov ebx, amount_threads - 1
.loop:
  mov esi, ebx
  mov edi, stats_tid_fmtstr
  mov eax, 0
  call printf

  ; Calculate the pointer to the thread struc from the thread ID.
  mov eax, thread_0_end - thread_0
  mul ebx
  add eax, threads
  mov ebx, eax

  mov rsi, [ebx + thread.exec_s_max]
  mov edi, stats_exec_s_max_fmtstr
  mov eax, 0
  call printf

  mov rsi, [ebx + thread.exec_s_size]
  mov edi, stats_exec_s_size_fmtstr
  mov eax, 0
  call printf

  mov rsi, [ebx + thread.execute_calls]
  add [rsp + thread.execute_calls], rsi
  mov edi, stats_execute_calls_fmtstr
  mov eax, 0
  call printf

  mov rsi, [ebx + thread.executed_mine]
  add [rsp + thread.executed_mine], rsi
  mov edi, stats_executed_mine_fmtstr
  mov eax, 0
  call printf

  mov rsi, [ebx + thread.needy]
  add [rsp + thread.needy], rsi
  mov edi, stats_needy_fmtstr
  mov eax, 0
  call printf

  mov rsi, [ebx + thread.sched_calls]
  add [rsp + thread.sched_calls], rsi
  mov edi, stats_sched_calls_fmtstr
  mov eax, 0
  call printf

  mov rsi, [ebx + thread.sched_mine]
  add [rsp + thread.sched_mine], rsi
  mov edi, stats_sched_mine_fmtstr
  mov eax, 0
  call printf

  mov rsi, [ebx + thread.alloc_s_max]
  mov edi, stats_alloc_s_max_fmtstr
  mov eax, 0
  call printf

  mov rsi, [ebx + thread.alloc_s_size]
  mov edi, stats_alloc_s_size_fmtstr
  mov eax, 0
  call printf

  mov rsi, [ebx + thread.allocate_calls]
  add [rsp + thread.allocate_calls], rsi
  mov edi, stats_allocate_calls_fmtstr
  mov eax, 0
  call printf

  mov rsi, [ebx + thread.alloc_orphans]
  add [rsp + thread.alloc_orphans], rsi
  mov edi, stats_alloc_orphans_fmtstr
  mov eax, 0
  call printf

  mov rsi, [ebx + thread.freed]
  add [rsp + thread.freed], rsi
  mov edi, stats_freed_fmtstr
  mov eax, 0
  call printf

  mov rsi, [ebx + thread.freed_orphans]
  add [rsp + thread.freed_orphans], rsi
  mov edi, stats_freed_orphans_fmtstr
  mov eax, 0
  call printf

  mov rsi, [ebx + thread.mmap]
  add [rsp + thread.mmap], rsi
  mov edi, stats_mmap_fmtstr
  mov eax, 0
  call printf

  mov eax, mmap_tasks * task_size / 1024
  mov rsi, [ebx + thread.mmap]
  mul rsi
  mov rsi, rdx
  mov rdx, rax
  mov edi, stats_mmap_kb_fmtstr
  mov eax, 0
  call printf

  ; Calculate the thread ID from the pointer to the thread struc.
  mov eax, ebx
  sub eax, threads
  xor edx, edx
  mov ebx, thread_0_end - thread_0
  div ebx
  mov ebx, eax
  sub ebx, 1
  jnc .loop

  mov esi, amount_threads
  mov edi, stats_total_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + thread.execute_calls]
  mov edi, stats_execute_calls_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + thread.executed_mine]
  mov edi, stats_executed_mine_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + thread.needy]
  mov edi, stats_needy_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + thread.sched_calls]
  mov edi, stats_sched_calls_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + thread.sched_mine]
  mov edi, stats_sched_mine_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + thread.allocate_calls]
  mov edi, stats_allocate_calls_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + thread.alloc_orphans]
  mov edi, stats_alloc_orphans_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + thread.freed]
  mov edi, stats_freed_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + thread.freed_orphans]
  mov edi, stats_freed_orphans_fmtstr
  mov eax, 0
  call printf

  mov rsi, [used_max]
  mov edi, stats_used_max_fmtstr
  mov eax, 0
  call printf

  mov rsi, [in_use]
  mov edi, stats_in_use_fmtstr
  mov eax, 0
  call printf

  mov rsi, [rsp + thread.mmap]
  mov edi, stats_mmap_fmtstr
  mov eax, 0
  call printf

  mov eax, mmap_tasks * task_size / 1024
  mov rsi, [rsp + thread.mmap]
  mul rsi
  mov rsi, rdx
  mov rdx, rax
  mov edi, stats_mmap_kb_fmtstr
  mov eax, 0
  call printf

  add rsp, thread_size
  ret

%endif




section .data  align=128

; Variables and strucs are aligned at 128-byte boundary because this improves
; cache-coherency performance, and because this improves the performance of
; processor bus locking used for atomic operations.  It also makes the needed
; 8-byte alignment for atomic field access.


; The global variable for indicating what thread needs a task.

needy: dd 0
align 128, db 0




; Threads' data strucs.

threads:

%assign n 0
%rep amount_threads

thread_%[n]:

istruc thread
  at thread.executables,    dq 0
  at thread.allocatables,   dq allocatables_%[n]_head
  at thread.gift,           dq 0
  at thread.orphans,        dq 0
%ifdef statistics_collection
  at thread.exec_s_max,     dq 0
  at thread.exec_s_size,    dq 0
  at thread.execute_calls,  dq 0
  at thread.executed_mine,  dq 0
  at thread.needy,          dq 0
  at thread.sched_calls,    dq 0
  at thread.sched_mine,     dq 0
  at thread.alloc_s_max,    dq statically_allocated_free_tasks
  at thread.alloc_s_size,   dq statically_allocated_free_tasks
  at thread.allocate_calls, dq 0
  at thread.alloc_orphans,  dq 0
  at thread.freed,          dq 0
  at thread.freed_orphans,  dq 0
  at thread.mmap,           dq 0
%endif
iend

align 128, db 0

thread_%[n]_end:  ; Used to know the aligned size, for offset calculation.

%assign n  n + 1
%endrep




; Statically-allocated and initialized task strucs for the allocatable-tasks
; stacks.  Task strucs are 128-bytes long, which preserves their 128-byte
; alignment when they are contiguously located like below.

%assign n 0
%rep amount_threads

allocatables_%[n]_head:

  istruc task
    at task.next,    dq allocatables_%[n]_1
    at task.owner,   dq thread_%[n]
    at task.rcvr,    dq 0
    at task.ridx,    dq 0
    at task.need,    dq 0
    at task.exec,    dq 0
    at task.arg1,    dq 0
    at task.arg2,    dq 0
    at task.arg3,    dq 0
    at task.arg4,    dq 0
    at task.arg5,    dq 0
    at task.arg6,    dq 0
    at task.arg7,    dq 0
    at task.arg8,    dq 0
    at task.arg9,    dq 0
    at task.arg10,   dq 0
  iend


allocatables_%[n]_1:

%assign a 2
%rep statically_allocated_free_tasks - 2

  istruc task
    at task.next,    dq allocatables_%[n]_%[a]
    at task.owner,   dq thread_%[n]
    at task.rcvr,    dq 0
    at task.ridx,    dq 0
    at task.need,    dq 0
    at task.exec,    dq 0
    at task.arg1,    dq 0
    at task.arg2,    dq 0
    at task.arg3,    dq 0
    at task.arg4,    dq 0
    at task.arg5,    dq 0
    at task.arg6,    dq 0
    at task.arg7,    dq 0
    at task.arg8,    dq 0
    at task.arg9,    dq 0
    at task.arg10,   dq 0
  iend

allocatables_%[n]_%[a]:

%assign a  a + 1
%endrep


  istruc task
    at task.next,    dq 0
    at task.owner,   dq thread_%[n]
    at task.rcvr,    dq 0
    at task.ridx,    dq 0
    at task.need,    dq 0
    at task.exec,    dq 0
    at task.arg1,    dq 0
    at task.arg2,    dq 0
    at task.arg3,    dq 0
    at task.arg4,    dq 0
    at task.arg5,    dq 0
    at task.arg6,    dq 0
    at task.arg7,    dq 0
    at task.arg8,    dq 0
    at task.arg9,    dq 0
    at task.arg10,   dq 0
  iend

%assign n  n + 1
%endrep




; The semaphore used by the main_race macro.

main_semaphore: dd 1




%ifdef statistics_collection

align 128, db 0

used_max:  dq 0
in_use:    dq 0

stats_tid_fmtstr:            db `Thread %lu:\n`,0
stats_exec_s_max_fmtstr:     db `  exec_s max:    %15llu\n`,0
stats_exec_s_size_fmtstr:    db `  exec_s size:   %15llu\n`,0
stats_execute_calls_fmtstr:  db `  execute calls: %15llu\n`,0
stats_executed_mine_fmtstr:  db `  executed mine: %15llu\n`,0
stats_needy_fmtstr:          db `  needy:         %15llu\n`,0
stats_sched_calls_fmtstr:    db `  sched calls:   %15llu\n`,0
stats_sched_mine_fmtstr:     db `  sched mine:    %15llu\n`,0
stats_alloc_s_max_fmtstr:    db `  alloc_s max:   %15llu\n`,0
stats_alloc_s_size_fmtstr:   db `  alloc_s size:  %15llu\n`,0
stats_allocate_calls_fmtstr: db `  allocate calls:%15llu\n`,0
stats_alloc_orphans_fmtstr:  db `  alloc orphans: %15llu\n`,0
stats_freed_fmtstr:          db `  freed:         %15llu\n`,0
stats_freed_orphans_fmtstr:  db `  freed orphans: %15llu\n`,0
stats_used_max_fmtstr:       db `  used max:      %15llu\n`,0
stats_in_use_fmtstr:         db `  in use:        %15llu\n`,0
stats_mmap_fmtstr:           db `  mmaps:         %15llu\n`,0
stats_mmap_kb_fmtstr:        db `  KB mmaped:     %llu,%llu\n`,0
stats_total_fmtstr:          db `Totals of %lu threads:\n`,0

%endif
