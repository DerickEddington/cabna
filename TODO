Investigate having a "thread" struc which defines the variables used by threads,
instead of using thread-specific offsets from global symbols.  This will place a
thread's variables closer, which might improve processor caching.  As long as it
doesn't degrade caching, it seems a cleaner way.  128-byte alignment still
necessary for some variables, for bus-locking and to avoid false sharing.

Investigate having, in addition to .needy, a .given variable where thread's
donate an executable-task to another thread instead of giving it in .needy.  The
giver atomically clears .needy, and the waiting thread waits on .given.  Does
this result in better cache behavior?

Investigate changing others_freed so that each thread only has one stack for
others to free to, instead of each thread having stacks for all other threads.
This will make the .data section size proportionate to the amount of threads,
instead of to the square of the amount of threads.  How does this affect
performance?  It seems unlikely that exclusion will happen much more or that the
spin-loop will last longer.

Investigate redesigning task giving so that there's only one global field that
indicates what thread needs a task.  Needy threads compete for setting the field
to indicate themselves.  Each thread has a field for receiving a gifted task.
After a thread sets the needy field, it waits for a pointer to appear in its
gift field.

Investigate a way to change sched_task to give the task to a needy thread
regardless of whether the executing thread's stack is empty, without degrading
performance.

Investigate if there's a point where multi-processor Cabna fibonacci is faster
than single-processor Ikarus fibonacci.

Review adding more comments for new designs.


Rename conv file to ?

Fix preprocessor error messages so the values, not symbols, are printed.

Is (un)likely actually a good idea?  Maybe not portable to other processors.
Seems to screw up objdump disassembly.  Review performance difference again.

Determine the stack size given to the initial thread.  Decide what size to give
other threads.  Minimum is 16384 (16 kb, 4 pages).

Review the optimization guideline points again.

Make a simple Scheme-like interpreter written in assembly and using the task
queueing and execution facilities.  I think this is an easy step towards using
the parallel processing without having a compiler.  Useful parallel programs
(including a compiler) can be interpreted.

Get rid of "bug" module.

Investigate what NASM directives are neccessary to make a shared library.

Investigate the performance difference of using common stack-based call/ret
instead of jmp_ret for Cabna procedures.  If the difference is neglegible, it
seems good to use Unix ABI calling convention so that other languages can call
Cabna procedures, which could be useful to some users.

Investigate supporting non-concurrent task execution, so that tasks can be
called without enqueueing in the exec queue and so that they return to the
caller, like common stack calling.  Is it even possible while also having the
task-enqueueing and task-taking concurrency design?  User procedures would have
to change so that it is dynamically parameterizable whether they enqueue tasks
or directly call them, otherwise directly-called procedures won't be done until
their enqueued sub-tasks are done, which won't happen until some thread(s)
dequeue and completely execute the sub-tasks, which will block the
direct-caller.  It's possible to have a register determine whether enqueue_task
or exec_task_directly is used for sub-tasks, but is it possible to generally
have a register determine whether a task continues to exec_avail or
free_pet__exec_avail or return_to_caller?  Supporting this would require using
call and ret and the stack, to allow nested direct procedure calls, otherwise
ret_rsi will be destroyed by calls in procedures' dynamic extents.  Supporting
this would, I think, require using a field of the currently executing task struc
for the return value of the directly-called procedure, i.e. the CET is the
receiver of the DCP so that the DCP can return its value in the same manner
regardless of whether it's called directly or executed from the queue; but, for
queued execution, when the CET is reused, it must be reused before the sub-tasks
are setup, but for direct calling it must be reused after so that it can be used
to receive the DCP's return value ???  ... However: maybe it's better for DCPs
to mot be tasks nor use the task execution facilities, but instead use common
stack-based call/ret.

Analyze object files / assembly / machine code again.
