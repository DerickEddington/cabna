Investigate why increasing the amount of threads well above the number of
processors results in less memory usage and faster execution.

Investigate the performance of making task memory management be such that each
thread has a private queue of tasks, not needing concurrency safety, but when
queue size reaches a limit, freed tasks are put in a shared concurrency-safe
queue, and when queue is empty, tasks are taken from the shared queue, and a
thread that finds the shared queue empty adds more via mmap.  This way, memory
is shared by all threads but locking/exclusion is avoiding much (most?) of the
time.

Rename conv file to ?

Investigate the performance of making threads spin-wait for their own exec queue
instead of trying other threads'.  Maybe rearrange jumping so that pause only
happens if spinning.  exec_avail still needs to try other threads' if its is
empty.

Investigate the performance of making threads indicate when they need a task to
execute, and making enqueue_task check if its thread's exec queue already has a
task and another thread needs a task and if so giving a task to the needy
thread.  Should the thread's oldest enqueued task should be given to the other
thread instead of the newest enqueued task?  This changes the design from
task-taking to task-giving.  What are the implications?  This relies on
enqueue_task being used in order for tasks to be given to another thread, and if
that doesn't happen, available threads won't be working.

Determine the stack size given to the initial thread.  Decide what size to give
other threads.  Minimum is 16384 (16 kb, 4 pages).

Review the optimization guideline points again.

Make a simple Scheme-like interpreter written in assembly and using the task
queueing and execution facilities.  I think this is an easy step towards using
the parallel processing without having a compiler.  Useful parallel programs
(including a compiler) can be interpreted.

Get rid of "bug" module.

Investigate what NASM directives are neccessary to make a shared library.

Investigate the performance difference of using common stack-based call/ret
instead of jmp_ret for Cabna procedures.  If the difference is neglegible, it
seems good to use Unix ABI calling convention so that other languages can call
Cabna procedures, which could be useful to some users.

Investigate supporting non-concurrent task execution, so that tasks can be
called without enqueueing in the exec queue and so that they return to the
caller, like common stack calling.  Is it even possible while also having the
task-enqueueing and task-taking concurrency design?  User procedures would have
to change so that it is dynamically parameterizable whether they enqueue tasks
or directly call them, otherwise directly-called procedures won't be done until
their enqueued sub-tasks are done, which won't happen until some thread(s)
dequeue and completely execute the sub-tasks, which will block the
direct-caller.  It's possible to have a register determine whether enqueue_task
or exec_task_directly is used for sub-tasks, but is it possible to generally
have a register determine whether a task continues to exec_avail or
free_pet__exec_avail or return_to_caller?  Supporting this would require using
call and ret and the stack, to allow nested direct procedure calls, otherwise
ret_rsi will be destroyed by calls in procedures' dynamic extents.  Supporting
this would, I think, require using a field of the currently executing task struc
for the return value of the directly-called procedure, i.e. the CET is the
receiver of the DCP so that the DCP can return its value in the same manner
regardless of whether it's called directly or executed from the queue; but, for
queued execution, when the CET is reused, it must be reused before the sub-tasks
are setup, but for direct calling it must be reused after so that it can be used
to receive the DCP's return value ???  ... However: maybe it's better for DCPs
to mot be tasks nor use the task execution facilities, but instead use common
stack-based call/ret.
